# ETL and Data Pipelines with Shell, Airflow and Kafka
For IBM Data Engineering Professional Certificate  

After taking this course, you will be able to describe two different approaches to converting raw data into analytics-ready data. One approach is the Extract, Transform, Load (ETL) process. The other contrasting approach is the Extract, Load, and Transform (ELT) process. ETL processes apply to data warehouses and data marts. ELT processes apply to data lakes, where the data is transformed on demand by the requesting/calling application.  

Both ETL and ELT extract data from source systems, move the data through the data pipeline, and store the data in destination systems. During this course, you will experience how ELT and ETL processing differ and identify use cases for both. 

You will identify methods and tools used for extracting the data, merging extracted data either logically or physically, and for importing data into data repositories.  You will also define transformations to apply to source data to make the data credible, contextual, and accessible to data users. You will be able to outline some of the multiple methods for loading data into the destination system, verifying data quality, monitoring load failures, and the use of recovery mechanisms in case of failure. 

- Week1 Data Processing Techniques
- Week2 ETL & Data Pipelines: Tools and Techniques
- Week3 Building Data Pipelines using Airflow
- Week4 Building Streaming Pipelines using Kafka
- Week5 Final Assignment
